"""
ULTIMATE COMPREHENSIVE DCFR TEST
- All games (Kuhn ‚Üí COLOSSAL)
- Memory profiling
- Iterations to convergence
- Time per iteration
- Adaptive vs Fixed
- ALL THE METRICS!
"""
import numpy as np
import time
import sys, os
import psutil
import tracemalloc
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from games.kuhn_structure import KuhnPokerStructureExtractor
from games.leduc_structure import LeducPokerStructureExtractor
from games.holdem_structure import (
    TinyHoldemExtractor, SimplifiedHoldemStructureExtractor,
    LargeHoldemExtractor, MassiveHoldemExtractor,
    UltraMassiveHoldemExtractor, GiganticHoldemExtractor,
    ColossalHoldemExtractor
)
from sparsification.sparse_payoff_matrix import SparsePayoffMatrix
from sparsification.general import ThresholdSparsification
import pyspiel
from game_tree import GameEnv


class ProfiledDCFR:
    """DCFR with complete profiling"""
    
    def __init__(self, structure, adaptive=True, name="DCFR"):
        self.structure = structure
        self.adaptive = adaptive
        self.name = name
        
        # DCFR parameters
        self.alpha = 1.5
        self.beta = 0.0
        self.gamma = 2.0
        
        # Sparsification
        self.current_threshold = 0.5 if adaptive else 0.2
        self.current_sparsifier = ThresholdSparsification(threshold=self.current_threshold)
        self.A = SparsePayoffMatrix(structure, self.current_sparsifier)
        
        self.n_seq = [self.A.m, self.A.n]
        
        # State
        self.x = [
            np.ones(self.n_seq[0]) / self.n_seq[0],
            np.ones(self.n_seq[1]) / self.n_seq[1]
        ]
        self.R = [np.zeros(self.n_seq[0]), np.zeros(self.n_seq[1])]
        self.x_sum = [np.zeros(self.n_seq[0]), np.zeros(self.n_seq[1])]
        
        self.t = 0
        self.total_time = 0.0
        
        # Profiling
        self.iteration_times = []
        self.exploit_history = []
        self.memory_samples = []
        
        # Adaptive
        self.check_interval = 500
        self.prev_max_regret = None
        self.adaptations = []
        
        # Get initial memory
        process = psutil.Process()
        self.initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    def iteration(self):
        """DCFR iteration with profiling"""
        iter_start = time.time()
        self.t += 1
        
        # Adaptive check
        if self.adaptive and self.t % self.check_interval == 0:
            self._check_and_adapt()
        
        # DCFR discounts
        t = self.t
        pos_discount = (t / (t + 1)) ** self.alpha
        neg_discount = (t / (t + 1)) ** self.beta
        strategy_discount = (t / (t + 1)) ** self.gamma
        
        for player in [0, 1]:
            if player == 0:
                grad = self.A.matvec(self.x[1])
            else:
                grad = -self.A.rmatvec(self.x[0])
            
            ev = np.dot(self.x[player], grad)
            regrets = grad - ev
            
            # Discount regrets
            self.R[player] *= pos_discount
            self.R[player] = np.where(
                self.R[player] > 0,
                self.R[player],
                self.R[player] * neg_discount
            )
            self.R[player] += regrets
            
            # Regret matching
            positive = np.maximum(self.R[player], 0)
            total = np.sum(positive)
            
            if total > 0:
                self.x[player] = positive / total
            else:
                self.x[player] = np.ones(self.n_seq[player]) / self.n_seq[player]
            
            # Discount strategy
            self.x_sum[player] *= strategy_discount
            self.x_sum[player] += self.x[player]
        
        iter_time = time.time() - iter_start
        self.iteration_times.append(iter_time)
        self.total_time += iter_time
        
        # Sample memory periodically
        if self.t % 100 == 0:
            process = psutil.Process()
            current_memory = process.memory_info().rss / 1024 / 1024  # MB
            self.memory_samples.append({
                'iter': self.t,
                'memory_mb': current_memory,
                'delta_mb': current_memory - self.initial_memory
            })
    
    def _check_and_adapt(self):
        """Adaptive sparsification"""
        max_regret = max(np.max(np.abs(self.R[0])), np.max(np.abs(self.R[1])))
        
        if self.prev_max_regret is None:
            self.prev_max_regret = max_regret
            return
        
        if self.prev_max_regret > 0:
            change_rate = abs(max_regret - self.prev_max_regret) / self.prev_max_regret
        else:
            change_rate = 1.0
        
        if change_rate < 0.1 and self.current_threshold > 0.05:
            new_threshold = max(0.05, self.current_threshold * 0.75)
            
            old_compression = self.A.compression_ratio
            self.current_threshold = new_threshold
            self.current_sparsifier = ThresholdSparsification(threshold=new_threshold)
            self.A = SparsePayoffMatrix(self.structure, self.current_sparsifier)
            new_compression = self.A.compression_ratio
            
            self.adaptations.append({
                'iter': self.t,
                'threshold': new_threshold,
                'compression_old': old_compression,
                'compression_new': new_compression,
                'max_regret': max_regret
            })
        
        self.prev_max_regret = max_regret
    
    def compute_exploitability(self):
        """Compute exploitability"""
        total = [np.sum(self.x_sum[p]) for p in range(2)]
        avg = [self.x_sum[p] / max(1, total[p]) for p in range(2)]
        
        br0 = self.A.matvec(avg[1])
        br1 = -self.A.rmatvec(avg[0])
        return np.max(br0) - np.dot(avg[0], br0) + np.max(br1) - np.dot(avg[1], br1)
    
    def record_exploit(self):
        """Record current exploitability"""
        exploit = self.compute_exploitability()
        self.exploit_history.append({
            'iter': self.t,
            'exploit': exploit,
            'time': self.total_time
        })
        return exploit
    
    def get_stats(self):
        """Get comprehensive statistics"""
        avg_iter_time = np.mean(self.iteration_times) if self.iteration_times else 0
        
        # Find convergence point (exploit < 0.01)
        convergence_iter = None
        convergence_time = None
        for record in self.exploit_history:
            if record['exploit'] < 0.01:
                convergence_iter = record['iter']
                convergence_time = record['time']
                break
        
        # Memory stats
        if self.memory_samples:
            peak_memory = max(s['memory_mb'] for s in self.memory_samples)
            avg_memory = np.mean([s['memory_mb'] for s in self.memory_samples])
            memory_growth = self.memory_samples[-1]['delta_mb']
        else:
            peak_memory = self.initial_memory
            avg_memory = self.initial_memory
            memory_growth = 0
        
        return {
            'total_iters': self.t,
            'total_time': self.total_time,
            'avg_iter_time_ms': avg_iter_time * 1000,
            'throughput': self.t / self.total_time if self.total_time > 0 else 0,
            'convergence_iter': convergence_iter,
            'convergence_time': convergence_time,
            'final_exploit': self.exploit_history[-1]['exploit'] if self.exploit_history else None,
            'initial_memory_mb': self.initial_memory,
            'peak_memory_mb': peak_memory,
            'avg_memory_mb': avg_memory,
            'memory_growth_mb': memory_growth,
            'adaptations': len(self.adaptations),
            'adaptation_details': self.adaptations
        }


def comprehensive_test_all_games():
    """Test ALL games with ALL metrics"""
    print("="*80)
    print("COMPREHENSIVE DCFR TEST: ALL GAMES, ALL METRICS")
    print("="*80)
    
    # Define all games with iteration budgets
    games = [
        ("Kuhn Poker", KuhnPokerStructureExtractor(), 5000, True),
        ("Leduc Poker", LeducPokerStructureExtractor(), 5000, True),
        ("Tiny Hold'em", TinyHoldemExtractor(), 2000, False),
        ("Simplified Hold'em (Preflop)", SimplifiedHoldemStructureExtractor(n_hand_buckets=5, include_flop=False), 2000, False),
        ("Simplified Hold'em (Full)", SimplifiedHoldemStructureExtractor(n_hand_buckets=5, include_flop=True), 1000, False),
        ("Large Hold'em", LargeHoldemExtractor(), 500, False),
        ("MASSIVE Hold'em", MassiveHoldemExtractor(), 200, False),
        ("ULTRA-MASSIVE Hold'em", UltraMassiveHoldemExtractor(), 50, False),  # Only 50!
        ("GIGANTIC Hold'em", GiganticHoldemExtractor(), 20, False),
        ("COLOSSAL Hold'em", ColossalHoldemExtractor(), 10, False),
    ]
    
    all_results = []
    
    for game_name, extractor, max_iters, use_openspiel in games:
        print(f"\n{'='*80}")
        print(f"GAME: {game_name}")
        print(f"{'='*80}")
        
        # Extract structure
        structure = extractor.extract_structure()
        
        # Game info
        m = len(structure.hands1) * structure.F.shape[0]
        n = len(structure.hands1) * structure.F.shape[1]
        matrix_size = m * n
        
        print(f"\nüìä Game Size:")
        print(f"   Matrix: {m:,} √ó {n:,} = {matrix_size:,} entries")
        print(f"   Memory (dense): {matrix_size * 8 / 1e9:.3f} GB")
        
        # Skip if too large
        if matrix_size > 100_000_000:  # > 100M entries
            print(f"\n   ‚ö†Ô∏è  Matrix too large for quick testing ({matrix_size:,} entries)")
            print(f"   ‚è≠Ô∏è  Skipping to next game...")
            continue
        
        # Setup game_env if needed
        if use_openspiel:
            try:
                game_env = GameEnv()
                game_name_lower = game_name.lower().replace(" ", "_").replace("'", "")
                game_env.load_open_spiel_game(pyspiel.load_game(game_name_lower))
            except:
                game_env = None
        else:
            game_env = None
        
        # Checkpoints
        checkpoints = [int(max_iters * p) for p in [0.2, 0.4, 0.6, 0.8, 1.0]]
        
        results = {
            'game': game_name,
            'matrix_size': matrix_size,
            'max_iters': max_iters
        }
        
        # Test both variants
        for variant_name, adaptive in [("Fixed", False), ("Adaptive", True)]:
            print(f"\n{'‚îÄ'*80}")
            print(f"Testing: {variant_name} DCFR")
            print(f"{'‚îÄ'*80}")
            
            # Start memory tracking
            tracemalloc.start()
            
            dcfr = ProfiledDCFR(structure, adaptive=adaptive, name=variant_name)
            
            checkpoint_idx = 0
            timeout = 120  # 2 minutes max per variant
            test_start = time.time()
            
            # Test first iteration to see how long it takes
            print(f"   Running test iteration...", end='')
            test_iter_start = time.time()
            dcfr.iteration()
            first_iter_time = time.time() - test_iter_start
            print(f" {first_iter_time*1000:.1f}ms")
            
            # Estimate total time
            estimated_total = first_iter_time * max_iters
            print(f"   Estimated total time: {estimated_total:.1f}s")
            
            if estimated_total > timeout:
                print(f"   ‚ö†Ô∏è  Would exceed timeout ({timeout}s), reducing iterations...")
                max_iters_adjusted = int(timeout / first_iter_time * 0.8)  # 80% safety margin
                checkpoints = [int(max_iters_adjusted * p) for p in [0.2, 0.4, 0.6, 0.8, 1.0]]
                print(f"   Adjusted to {max_iters_adjusted} iterations")
            else:
                max_iters_adjusted = max_iters
            
            # Run remaining iterations
            for i in range(1, max_iters_adjusted):  # Start from 1 since we did one already
                # Check timeout
                if time.time() - test_start > timeout:
                    print(f"\n   ‚è±Ô∏è  Timeout reached at {i+1} iterations")
                    break
                
                dcfr.iteration()
                
                # Progress indicator
                if (i + 1) % max(1, max_iters_adjusted // 20) == 0:
                    elapsed = time.time() - test_start
                    progress = (i + 1) / max_iters_adjusted * 100
                    eta = elapsed / (i + 1) * max_iters_adjusted - elapsed
                    print(f"      Progress: {i+1}/{max_iters_adjusted} ({progress:.0f}%) | Elapsed: {elapsed:.1f}s | ETA: {eta:.1f}s", end='\r')
                
                # Record at checkpoints
                if checkpoint_idx < len(checkpoints) and (i + 1) == checkpoints[checkpoint_idx]:
                    exploit = dcfr.record_exploit()
                    print(f"\n   Checkpoint {i+1}/{max_iters_adjusted}: exploit={exploit:.6f}, time={dcfr.total_time:.2f}s")
                    checkpoint_idx += 1
                    if checkpoint_idx >= len(checkpoints):
                        break
            
            print()  # New line after progress
            
            # Get final stats
            stats = dcfr.get_stats()
            tracemalloc.stop()
            
            # Print summary
            print(f"\n   üìä {variant_name} Summary:")
            print(f"      Total iterations: {stats['total_iters']}")
            print(f"      Total time: {stats['total_time']:.2f}s")
            print(f"      Avg time/iter: {stats['avg_iter_time_ms']:.3f}ms")
            print(f"      Throughput: {stats['throughput']:.0f} iter/sec")
            print(f"      Final exploit: {stats['final_exploit']:.6f}")
            
            if stats['convergence_iter']:
                print(f"      ‚úÖ Converged at iter {stats['convergence_iter']} ({stats['convergence_time']:.2f}s)")
            else:
                print(f"      ‚ö†Ô∏è  Did not converge to < 0.01")
            
            print(f"      Memory (initial): {stats['initial_memory_mb']:.1f} MB")
            print(f"      Memory (peak): {stats['peak_memory_mb']:.1f} MB")
            print(f"      Memory (growth): {stats['memory_growth_mb']:.1f} MB")
            
            if adaptive and stats['adaptations'] > 0:
                print(f"      Adaptations: {stats['adaptations']}")
                for adapt in stats['adaptation_details']:
                    print(f"         Iter {adapt['iter']}: threshold {adapt['threshold']:.2f}, compression {adapt['compression_new']*100:.1f}%")
            
            results[variant_name.lower()] = stats
        
        # Compare (rest of code stays the same)
        # ... (keep all comparison code)
        
        all_results.append(results)
    
    # MASTER SUMMARY TABLE (same as before)
    # ...
    
    return all_results


if __name__ == '__main__':
    results = comprehensive_test_all_games()
    
    print("\n\nüìä TEST COMPLETE! All metrics collected.")
    print("   - Convergence rates")
    print("   - Time per iteration")
    print("   - Memory usage")
    print("   - Adaptive vs Fixed comparison")
    print("   - Tested on 10 different game sizes")